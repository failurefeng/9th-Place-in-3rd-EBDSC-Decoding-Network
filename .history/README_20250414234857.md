# README
这是“哪吒真不会解码”团队在第三届电磁大数据非凡挑战赛中使用的解码网络的训练和测试代码。

# Requirements
```
matplotlib==3.3.* #根据matplotlib的版本历史，matplotlib 3.3.x是最后一个支持Python 3.8的系列。
ptflops==0.7.2.2 # 根据官方文档，如果您使用的是PyTorch 1.x版本，推荐使用ptflops==0.7.2.2
fvcore # 实际反馈：Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-3.0.0 pyyaml-6.0.2 tabulate-0.9.0 termcolor-2.4.0 tqdm-4.67.1 yacs-0.1.8
thop # 实际反馈：Successfully installed thop-0.1.1.post2209072238
h5py # 实际反馈：Successfully installed h5py-3.11.0

pandas # 实际反馈：Successfully installed pandas-2.0.3 pytz-2024.2 tzdata-2024.2

tables # version=3.8.0
torchsummaryX # Successfully installed torchsummaryX-1.3.0
einops # Successfully installed einops-0.8.0

# 为了使用flash-attn加速transformer训练并减小显存占用，我又卸载了原来的torch系列，新的下载命令如下：
torch==2.1.0
torchaudio==2.1.0
torchvision==0.16.0
flash_attn==2.4.1
```

# Architecture
``` 
home
├── amr/
│   ├── dataloaders/
│   ├── models/
│   │   ├── losses/
│   │   ├── networks/
│   ├── utils/
│   │   ├── __init__.py
│   │   ├── config.py
│   │   ├── draw.py
│   │   ├── init.py
│   │   ├── logger.py
│   │   ├── solver.py
│   │   ├── static.py
├── configs/
│   ├── *.yaml
├── main.py
├── complexity.py
├── datasets/
├── results/
```

# Train and Test Your Own Model
1. 准备好数据集文件: './dataset_file\data_fil_split3.h5'

2. 训练和测试模型: 在终端运行 `python main.py`

3. 查看结果: 在 `results/`中查看训练好的模型、训练过程数据和可视化结果. 


# Result Reproduction
1. 准备好数据集文件: './dataset_file\data_fil_split3.h5'

2. 准备模型权重文件: 我提供了训练好的模型权重文件 `results/demod/setp3/best_CQ.pth` ，还有一些训练过程数据和可视化结果放在`results/demod\setp3/`中。

3. 修改设置: set the parameter `train` From `True` to `False` in `configs/transformerlstm_ours.yaml` ,然后在终端运行 `python main.py`来获取结果 .

    e.g.
    ```yaml for RadioML2016.10a
    modes:  
        method: 'TransformerLSTM'
        path: 'best' # save address
        loss: 'loss_CE'
        train: False # set the parameter: from True to False
        ddp: False # choose whether to use ddp trainint
    data_settings:  
        dataset: 'RML2016'
        Xmode:
            type: 'AP' # input type for the model
            options:
                IQ_norm: False # choose whether to normalized the input signal
                zero_mask: False
                random_mix: False #choose whether to use the random mixing strategy
        mod_type: ['8PSK', 'AM-DSB', 'AM-SSB', 'BPSK', 'CPFSK', 'GFSK', 'PAM4', 'QAM16', 'QAM64', 'QPSK', 'WBFM']
    opt_params: 
        batch_size: 128
        epochs: 150
        lr: 1e-3
        workers: 8
        seed: 1
        gpu: 0
        cpu: False
        early_stop: False
    ```

    ```yaml for RadioML2018.01a
    modes:  
        method: 'TransformerLSTM'
        path: 'best'
        loss: 'loss_CE'
        train: False # set the parameter: from True to False
        ddp: False
    data_settings:  
        dataset: 'RML2018'
        Xmode:
            type: 'AP'
            options:
                IQ_norm: False 
                zero_mask: False
                random_mix: False
        mod_type: [ '32PSK', '16APSK', '32QAM', 'FM', 'GMSK', '32APSK', 'OQPSK', '8ASK', 'BPSK', '8PSK', 'AM-SSB-SC',
        '4ASK', '16PSK', '64APSK', '128QAM', '128APSK', 'AM-DSB-SC', 'AM-SSB-WC', '64QAM', 'QPSK', '256QAM',
        'AM-DSB-WC', 'OOK', '16QAM' ]
    opt_params:  
        batch_size: 400
        epochs: 150
        lr: 1e-3
        workers: 8
        seed: 1
        gpu: 0
        cpu: False
        early_stop: False
    ```




